a1.sources = s1
a1.channels = c1
a1.sinks = k1


# For each one of the sources, the type is defined
a1.sources.s1.type = spooldir
a1.sources.s1.channels = c1
a1.sources.s1.spoolDir = /data/flume/source


# Each sink's type must be defined
a1.sinks.k1.type = hdfs 
a1.sinks.k1.hdfs.path = hdfs://192.168.0.102:9000/flume
a1.sinks.k1.hdfs.filePrefix = events-
# hfds上目录使用了时间转换符 %y-%m-%d
a1.sinks.k1.hdfs.useLocalTimeStamp = true
# 用文本文件，不使用sequenceFile
a1.sinks.k1.hdfs.fileType = DataStream
a1.sinks.k1.hdfs.writeFormat=TEXT
# hfds上文件目录创建的频率 
#a1.sinks.k1.hdfs.round = true
#a1.sinks.k1.hdfs.roundValue = 10
#a1.sinks.k1.hdfs.roundUnit = minute
# 多长时间写数据到新文件
a1.sinks.k1.hdfs.rollInterval = 0
# 文件达到多少数据量时 写新文件
# 文件大小 接近于一个Block的大小 128M  ~ 120M左右
a1.sinks.k1.hdfs.rollSize = 0
# 文件已经写了多次次之后，写新文件
a1.sinks.k1.hdfs.rollCount = 1024
a1.sinks.k1.channel = c1


# Each channel's type is defined.
a1.channels.c1.type = memory
a1.channels.c1.transactionCapacity=100
a1.channels.c1.capacity = 10000